# RANDOM FACTORS:   m[p], c[p], epsilon[p], alpha[p]
# HYPER-PRIORS ON:  none

model{

# DISCOUNT FUNCTION PARAMETERS =================================================
# RANDOM (BY PARTICIPANT) FACTORS; HYPER-PRIORS = NO

for (p in 1:nRealExperimentFiles){
    mc_mu[p,1] ~ dnorm(-0.243, 1/( (0.027)^2)) # prior over m_mu
    mc_mu[p,2] ~ dnorm(-3    , 1/( 2^2) )      # prior over c_mu
    precision[p,1] ~ dgamma(0.001,0.001)
    precision[p,2] ~ dgamma(0.001,0.001)
    r[p] ~ dunif(-1,1)

    # reparameterise
    sigma[p,1] <- 1/sqrt(precision[p,1])
    sigma[p,2] <- 1/sqrt(precision[p,2])
    T[p,1,1] <- 1/precision[p,1]
    T[p,1,2] <- r[p]*sigma[p,1]*sigma[p,2]
    T[p,2,1] <- r[p]*sigma[p,1]*sigma[p,2]
    T[p,2,2] <- 1/precision[p,2]
    TI[p,1:2,1:2] <- inverse(T[p,1:2,1:2])

    mc[p,1:2] ~ dmnorm(mc_mu[p,1:2],TI[p,1:2,1:2])

    m[p] <- mc[p,1]
    c[p] <- mc[p,2]
}

for (t in 1:length(ID)) {
	# MAGNITUDE EFFECT: what is log(k) on this trial?
	lkA[t] <- m[ID[t]]*log(abs(A[t]))+c[ID[t]]
	lkB[t] <- m[ID[t]]*log(abs(B[t]))+c[ID[t]]

	# calculate present subjective value for each reward
	VA[t] <- A[t] / (1+(exp(lkA[t])*DA[t]))
	VB[t] <- B[t] / (1+(exp(lkB[t])*DB[t]))
}

# RESPONSE ERROR PARAMETERS ====================================================
epsilon_alpha <- 1+1
epsilon_beta <- 1+10
for (p in 1:nRealExperimentFiles){
	alpha[p]   ~ dexp(0.01)
	epsilon[p] ~ dbeta(epsilon_alpha , epsilon_beta ) T(,0.5)
}


# MODEL IN-SPECIFIC CODE BELOW... SHOULD NOT CHANGE ACROSS MODELS ==============

# Psychometric function
for (t in 1:length(ID)) {
	P[t] <- epsilon[ID[t]] + (1-2*epsilon[ID[t]]) * phi( (VB[t]-VA[t]) / alpha[ID[t]] )
}

# response likelihood
for (t in 1:length(ID)) {
	R[t]  ~ dbern(P[t]) # likelihood of actual response
	log_lik[t] <- logdensity.bern(R[t], P[t])
}

# POSTERIOR PREDICTION
for (t in 1:length(ID)) {
	Rpostpred[t] ~ dbern(P[t])
}


}
